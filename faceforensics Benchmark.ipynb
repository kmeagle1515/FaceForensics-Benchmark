{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras in /usr/local/lib/python3.5/dist-packages (2.3.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from Keras) (5.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.5/dist-packages (from Keras) (1.0.5)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.5/dist-packages (from Keras) (1.0.6)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from Keras) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from Keras) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from Keras) (1.14.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from Keras) (1.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "!pip install Keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import densenet\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import multi_gpu_model\n",
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "# from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "nb_train_samples = 539231\n",
    "nb_validation_samples = 240424\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 539231 images belonging to 2 classes.\n",
      "Found 240424 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = \"../../../../../raid/Data/Master_Dataset/mix/train\"\n",
    "validation_data_dir = \"../../../../../raid/Data/Master_Dataset/mix/validation\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode = 'constant',\n",
    "    cval = 1,\n",
    "    rotation_range = 5,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "base_model = densenet.DenseNet121(input_shape=(img_width, img_height, 3),\n",
    "                                     weights=\"densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n",
    "                                     include_top=False,\n",
    "                                     pooling='avg')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "x = base_model.output\n",
    "x = Dense(n_classes, activation='sigmoid', name = 'prediction')(x)\n",
    "model = Model(inputs = base_model.input, outputs = x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto',min_delta=1e-2, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=1, mode='auto',verbose=1, min_delta=1e-2, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "class LossHistory(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global i\n",
    "        self.model.save(\"paper/weights_of_epoch_\" + str(i) + \".hdf5\")\n",
    "#         summarize_diagnostics(self.model_history, i)\n",
    "        i += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "5392/5392 [==============================] - 7986s 1s/step - loss: 0.1242 - accuracy: 0.9480 - val_loss: 0.4775 - val_accuracy: 0.8698\n",
      "Epoch 2/10\n",
      "5392/5392 [==============================] - 7788s 1s/step - loss: 0.0488 - accuracy: 0.9807 - val_loss: 0.3897 - val_accuracy: 0.8513\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 3/10\n",
      "5392/5392 [==============================] - 7153s 1s/step - loss: 0.0301 - accuracy: 0.9884 - val_loss: 0.3937 - val_accuracy: 0.8819\n",
      "Epoch 4/10\n",
      "5392/5392 [==============================] - 7007s 1s/step - loss: 0.0272 - accuracy: 0.9893 - val_loss: 0.4800 - val_accuracy: 0.8827\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 5/10\n",
      "5392/5392 [==============================] - 6853s 1s/step - loss: 0.0249 - accuracy: 0.9903 - val_loss: 0.5188 - val_accuracy: 0.8909\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "e = 10\n",
    "# model = tf.keras.models.load_model('/home/vision/mrunal/detect_deepfake/densenet121/paper/weights_of_epoch_0.hdf5')\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model = multi_gpu_model(model, gpus=2)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "final_location = []\n",
    "lh = LossHistory()\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [lh, early_stop, reduce_lr]\n",
    "\n",
    "model_history = model.fit_generator(\n",
    "train_generator,\n",
    "epochs=e,\n",
    "steps_per_epoch = nb_train_samples // train_generator.batch_size,\n",
    "validation_data=validation_generator,\n",
    "verbose=1,\n",
    "validation_steps=nb_validation_samples // validation_generator.batch_size,\n",
    "callbacks=callbacks_list)\n",
    "\n",
    "#model.save(\"weights_best_\" + str(e) + \".hdf5\")\n",
    "\n",
    "# _,acc=model.evaluate_generator(validation_generator, steps=nb_validation_samples, max_queue_size=10,verbose=1, workers=1, use_multiprocessing=False)\n",
    "# print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "loss=model_history.history['loss']\n",
    "acc=model_history.history['accuracy']\n",
    "valacc=model_history.history['val_accuracy']\n",
    "valloss=model_history.history['val_loss']\n",
    "location = [e,loss,acc,valacc, valloss]\n",
    "final_location.append(location)\n",
    "save = pd.DataFrame(final_location,columns=['epochs','loss','acc','valacc','valloss'])\n",
    "save.to_csv('/home/vision/mrunal/detect_deepfake/densenet121/paper/densenet_log_'+str(e)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras in /usr/local/lib/python3.5/dist-packages (2.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from Keras) (1.3.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from Keras) (5.3)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from Keras) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from Keras) (1.14.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.5/dist-packages (from Keras) (1.0.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from Keras) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.5/dist-packages (from Keras) (1.0.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.1.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# PREDICTIONS TESTING\n",
    "%%bash\n",
    "pip install Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.models.load_model(\"densenet121/paper/weights_of_epoch_1.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            7038529     lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Concatenate)        (None, 1)            0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,038,529\n",
      "Trainable params: 6,954,881\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:44<00:00, 26.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# ff benchmark\n",
    "from keras.preprocessing.image  import load_img, img_to_array\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "test_data_dir = \"/home/vision/mrunal/faceforensics_benchmark_images\"\n",
    "final_predictions = []\n",
    "# for classes in os.listdir(test_data_dir):\n",
    "#     class_path = os.path.join(test_data_dir, classes)\n",
    "\n",
    "for images in tqdm(os.listdir(test_data_dir)):\n",
    "    file_path = os.path.join(test_data_dir, images)\n",
    "    image = load_img(file_path, target_size = (224,224))\n",
    "    array_image = img_to_array(image)\n",
    "    array_image = array_image*(1./255)\n",
    "    array_image = np.expand_dims(array_image, axis = 0)\n",
    "    result = model.predict(array_image)\n",
    "    final_predictions.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
